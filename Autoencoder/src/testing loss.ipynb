{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rjpg/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 200)          88000     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 188,905\n",
      "Trainable params: 188,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "dfin = pd.read_csv('../NNNormalizeDataIn.csv',header=None)  #inputs 128 lines per sample\n",
    "dfout = pd.read_csv('../NNNormalizeDataOutClassses.csv',header=None)  #output classes \n",
    "\n",
    "total_inputs,total_output = dfin.as_matrix().astype(np.float32),dfout.as_matrix().astype(np.int32)\n",
    "\n",
    "total_inputs = np.reshape(total_inputs, (-1,128,9))\n",
    "\n",
    "train_inputs, test_inputs, train_output, test_output = train_test_split(total_inputs, total_output, test_size=0.2, random_state=42)\n",
    "\n",
    "NB_EPOCH = 5\n",
    "# network and training\n",
    "BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "IMG_ROWS, IMG_COLS = 128, 5 \n",
    "NB_CLASSES = 5 \n",
    "INPUT_SHAPE = (1, IMG_ROWS, IMG_COLS)\n",
    "\n",
    "X_train = train_inputs\n",
    "y_train = np_utils.to_categorical(train_output, NB_CLASSES)\n",
    "X_test = test_inputs\n",
    "y_test = np_utils.to_categorical(test_output, NB_CLASSES)\n",
    "\n",
    "\n",
    "class LSTMNet:\n",
    "    @staticmethod\n",
    "    def build(timeSteps,variables,classes):\n",
    "        inputNet = Input(shape=(timeSteps,variables)) \n",
    "       \n",
    "        lstm=Bidirectional(LSTM(100,recurrent_dropout=0.4,dropout=0.4,return_sequences=True),merge_mode='concat')(inputNet) #worse using stateful=True\n",
    "        lstm=Bidirectional(LSTM(50,recurrent_dropout=0.4,dropout=0.4,return_sequences=False),merge_mode='concat')(lstm) #worse using stateful=True \n",
    "        \n",
    "        classificationLayer=Dense(classes,activation='softmax')(lstm)\n",
    "        \n",
    "        model=Model(inputNet,classificationLayer)\n",
    "        return model\n",
    "    \n",
    "modellstm = LSTMNet.build(timeSteps=128,variables=9,classes=5)\n",
    "modellstm.summary()\n",
    "\n",
    "#K.categorical_crossentropy\n",
    "\n",
    "modellstm.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER,metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "#modellstm.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER,metrics=[\"accuracy\"])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1660 samples, validate on 415 samples\n",
      "Epoch 1/5\n",
      "46s - loss: 1.6078 - acc: 0.2169 - val_loss: 1.5977 - val_acc: 0.2434\n",
      "Epoch 2/5\n",
      "55s - loss: 1.5996 - acc: 0.2295 - val_loss: 1.5844 - val_acc: 0.2675\n",
      "Epoch 3/5\n",
      "56s - loss: 1.5830 - acc: 0.2620 - val_loss: 1.5759 - val_acc: 0.2578\n",
      "Epoch 4/5\n",
      "53s - loss: 1.5815 - acc: 0.2723 - val_loss: 1.5732 - val_acc: 0.2771\n",
      "Epoch 5/5\n",
      "50s - loss: 1.5694 - acc: 0.2783 - val_loss: 1.5669 - val_acc: 0.2723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = modellstm.fit(X_train, y_train, \n",
    "        batch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "        verbose=2,\n",
    "        validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 128, 200)          88000     \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 188,905\n",
      "Trainable params: 188,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modellstm2 = LSTMNet.build(timeSteps=128,variables=9,classes=5)\n",
    "modellstm2.summary()\n",
    "\n",
    "modellstm2.compile(loss=K.categorical_crossentropy, optimizer=OPTIMIZER,metrics=[\"accuracy\"])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1660 samples, validate on 415 samples\n",
      "Epoch 1/5\n",
      "53s - loss: 12.8783 - acc: 0.2114 - val_loss: 12.8372 - val_acc: 0.2361\n",
      "Epoch 2/5\n",
      "59s - loss: 12.7791 - acc: 0.2446 - val_loss: 12.7565 - val_acc: 0.2193\n",
      "Epoch 3/5\n",
      "62s - loss: 12.6016 - acc: 0.2494 - val_loss: 12.6343 - val_acc: 0.2217\n",
      "Epoch 4/5\n",
      "57s - loss: 12.3212 - acc: 0.2452 - val_loss: 12.3410 - val_acc: 0.2410\n",
      "Epoch 5/5\n",
      "64s - loss: 12.0311 - acc: 0.2693 - val_loss: 12.2590 - val_acc: 0.2337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history = modellstm2.fit(X_train, y_train, \n",
    "        batch_size=BATCH_SIZE, epochs=NB_EPOCH, \n",
    "        verbose=2,\n",
    "        validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
