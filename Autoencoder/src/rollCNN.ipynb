{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Lambda, Dropout \n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import merge,Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "from keras.engine.topology import Layer,InputSpec\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CylindricalPad\n"
     ]
    }
   ],
   "source": [
    "class CylindricalPad(Layer):\n",
    "\n",
    "    def __init__(self, n=1, **kwargs):\n",
    "        super(CylindricalPad, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "        assert n > 0, 'n must be positive'\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        super(CylindricalPad, self).build(input_shape)  \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    input_shape[2],\n",
    "                    input_shape[3] + 2*self.n)\n",
    "            \n",
    "    def call(self, elementA, mask=None):\n",
    "        element=elementA\n",
    "        batchResultFlat=[]\n",
    "        for batchElement in element:\n",
    "            resultFlat=[]\n",
    "            for cnnFilterImage in batchElement:\n",
    "                firstColumns=cnnFilterImage[:,list(range(self.n))]\n",
    "                result=np.concatenate((cnnFilterImage,np.array(firstColumns)),axis=1)\n",
    "                lastColumnsReverse=cnnFilterImage[:,list(range(cnnFilterImage.shape[1]-self.n,cnnFilterImage.shape[1]))]\n",
    "                result=np.concatenate((np.array(lastColumnsReverse),result),axis=1)\n",
    "                resultFlat.append(result)\n",
    "            batchResultFlat.append(np.array(resultFlat))\n",
    "        newElement = np.array(batchResultFlat)\n",
    "        return newElement\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'cropping': self.cropping}\n",
    "        base_config = super(Cropping2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "print(\"CylindricalPad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f4ba2f663e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodeltest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRJPGNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeSteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mmodeltest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adadelta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodeltest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f4ba2f663e42>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(timeSteps, variables, classes)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mconv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCylindricalPad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m################################# OR ##################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#conv1=Lambda(lambda element : transformTest(element,2))(conv1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-846f5f105716>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, elementA, mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melementA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatchResultFlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchElement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mresultFlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcnnFilterImage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatchElement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m       raise TypeError(\n\u001b[0;32m--> 436\u001b[0;31m           \u001b[0;34m\"Tensor objects are not iterable when eager execution is not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    438\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are not iterable when eager execution is not enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "\n",
    "K.set_image_dim_ordering(\"th\")\n",
    "\n",
    "def transform(element,n):\n",
    "    batchResultFlat=[]\n",
    "    for batchElement in element:\n",
    "        resultFlat=[]\n",
    "        for cnnFilterImage in batchElement:\n",
    "            print(cnnFilterImage)\n",
    "            firstColumns=cnnFilterImage[:,list(range(n))]\n",
    "            print( np.array(firstColumns))\n",
    "            result=np.concatenate((cnnFilterImage,np.array(firstColumns)),axis=1)\n",
    "            print(result)\n",
    "            print(np.flipud(list(range(cnnFilterImage.shape[1]-n,cnnFilterImage.shape[1]))))\n",
    "            #lastColumnsReverse=cnnFilterImage[:,np.flipud(list(range(cnnFilterImage.shape[1]-n,cnnFilterImage.shape[1])))]\n",
    "            lastColumnsReverse=cnnFilterImage[:,list(range(cnnFilterImage.shape[1]-n,cnnFilterImage.shape[1]))]\n",
    "            print(lastColumnsReverse)\n",
    "            result=np.concatenate((np.array(lastColumnsReverse),result),axis=1)\n",
    "            print(result)\n",
    "            resultFlat.append(result)\n",
    "        batchResultFlat.append(np.array(resultFlat))\n",
    "    print(np.array(batchResultFlat))\n",
    "    newElement = np.array(batchResultFlat)\n",
    "    return newElement\n",
    "\n",
    "def transformTest(element,n):\n",
    "    if element.ndims > 0:\n",
    "        return tf.map_fn(transformTest, inputs)\n",
    "    else:\n",
    "        return transform(inputs,n)\n",
    "    return element\n",
    "\n",
    "class RJPGNet:\n",
    "    @staticmethod\n",
    "    def build(timeSteps,variables,classes):\n",
    "        #CONV=>POOL\n",
    "        inputNet = Input(shape=(1,timeSteps,variables)) \n",
    "        conv1=Conv2D(20, (2,5), padding=\"same\")(inputNet)\n",
    "        \n",
    "        #######################################################################\n",
    "        conv1=CylindricalPad(n=2)(conv1)\n",
    "        ################################# OR ##################################\n",
    "        #conv1=Lambda(lambda element : transformTest(element,2))(conv1)\n",
    "        #######################################################################\n",
    "        \n",
    "        conv2=Conv2D(5,(3,3), padding=\"same\")(conv1)\n",
    "        \n",
    "        flatten=Flatten()(conv2)\n",
    "                \n",
    "        classificationLayer=Dense(classes)(flatten)\n",
    "        classificationLayer=Activation(\"softmax\")(classificationLayer)\n",
    "        \n",
    "        model=Model(inputNet,classificationLayer)\n",
    "        return model\n",
    "    \n",
    "\n",
    "    \n",
    "modeltest=RJPGNet.build(timeSteps=7,variables=5,classes=5)\n",
    "modeltest.compile(optimizer=\"adadelta\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "modeltest.summary() \n",
    "\n",
    "#plot_model(modeltest, to_file=\"model.png\",show_shapes=True)\n",
    "\n",
    "#plot_model(modeltest, to_file=\"model.png\",show_shapes=True)\n",
    "from IPython.display import SVG,display\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "modelSVG=SVG(model_to_dot(modeltest,show_shapes=True).create(prog='dot', format='svg'))\n",
    "display(modelSVG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
